# Random Forests

[The Mechanics of Machine Learning](https://mlbook.explained.ai/):

> How much we care about cleaning up the data depends on the model we're using and whether the offending values are in predictor variables \(features\) or the target. One of the advantages of RFs is that they deal gracefully with errors and outliers in the predictor variables. RFs behave like nearest-neighbor models and feature outliers are partitioned off into lonely corners of the feature space automatically.

