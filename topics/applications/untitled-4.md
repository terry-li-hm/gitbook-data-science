# NLP

[Data Analysis & XGBoost Starter \(0.35460 LB\) \| Kaggle](https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb)

[Bag of Words Meets Bags of Popcorn \| Kaggle](https://www.kaggle.com/c/word2vec-nlp-tutorial#description)

[Working With Text Data â€” scikit-learn 0.19.1 documentation](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)

[sloria/TextBlob: Simple, Pythonic, text processing--Sentiment analysis, part-of-speech tagging, noun phrase extraction, translation, and more.](https://github.com/sloria/textblob)

[Getting Started with spaCy for Natural Language Processing](https://www.kdnuggets.com/2018/05/getting-started-spacy-natural-language-processing.html)

[How I lost a silver medal in Kaggleâ€™s Mercari Price Suggestion Challenge using CNNs and Tensorflow](https://medium.com/unstructured/how-i-lost-a-silver-medal-in-kaggles-mercari-price-suggestion-challenge-using-cnns-and-tensorflow-4013660fcded)

[Understanding Feature Engineering \(Part 4\) â€” Deep Learning Methods for Text Data](https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa)

[fastText/pretrained-vectors.md at master Â· facebookresearch/fastText](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md)

[Kyubyong/nlp\_tasks: Natural Language Processing Tasks and References](https://github.com/Kyubyong/nlp_tasks)

[xiamx/awesome-sentiment-analysis: ğŸ˜€ğŸ˜„ğŸ˜‚ğŸ˜­ A curated list of Sentiment Analysis methods, implementations and misc. ğŸ˜¥ğŸ˜ŸğŸ˜±ğŸ˜¤](https://github.com/xiamx/awesome-sentiment-analysis)

[The Essential NLP Guide for data scientists \(codes for top 10 NLP tasks\)](https://www.analyticsvidhya.com/blog/2017/10/essential-nlp-guide-data-scientists-top-10-nlp-tasks/)

[How to solve 90% of NLP problems: a step-by-step guide](https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e)

[What is TF-IDF? The 10 minute guide](http://michaelerasm.us/post/tf-idf-in-10-minutes/)

According to [Wikipedia](https://en.wikipedia.org/wiki/Word_embedding):

> Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing \(NLP\) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with much lower dimension.

Further readings:[https://www.quora.com/What-does-the-word-embedding-mean-in-the-context-of-Machine-Learning/answer/Julien-Despois](https://www.quora.com/What-does-the-word-embedding-mean-in-the-context-of-Machine-Learning/answer/Julien-Despois)[https://www.tensorflow.org/tutorials/word2vec\#motivation\_why\_learn\_word\_embeddings](https://www.tensorflow.org/tutorials/word2vec#motivation_why_learn_word_embeddings)[https://www.zhihu.com/question/32275069](https://www.zhihu.com/question/32275069)

[Awesome-Chinese-NLP: A curated list of resources for Chinese NLP ä¸­æ–‡è‡ªç„¶èªè¨€è™•ç†ç›¸é—œè³‡æ–™](https://github.com/crownpku/Awesome-Chinese-NLP)

[Natural Language Processing Key Terms, Explained](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)



* [How can I tokenize a sentence with Python?](https://www.oreilly.com/learning/how-can-i-tokenize-a-sentence-with-python)
* [è‡ªç„¶èªè¨€è™•ç†å¾å…¥é–€åˆ°é€²éšè³‡ä»£ç¢¼è³‡æºåº«å½™ç¸½ï¼ˆéš¨æ™‚æ›´æ–°ï¼‰](https://zhuanlan.zhihu.com/p/28616862)
* [è‰¾ä¼¦AIç ”ç©¶é™¢å‘å¸ƒAllenNLPï¼šåŸºäºPyTorchçš„NLPå·¥å…·åŒ…](https://www.jiqizhixin.com/articles/2017-09-09-5)
* [Deep Learning for NLP Best Practices](http://ruder.io/deep-learning-nlp-best-practices/)
* [Topic Modelling Financial News with Natural Language Processing](http://mattmurray.net/topic-modelling-financial-news-with-natural-language-processing/)
* [Best Practices for Document Classification with Deep Learning](https://machinelearningmastery.com/best-practices-document-classification-deep-learning/)
* [Natural Language Processing in Artificial Intelligence is almost human-level accurate. Worse yet, it gets smart!](https://sigmoidal.io/boosting-your-solutions-with-nlp/)
* [Word vectors for non-NLP data and research people](https://medium.com/towards-data-science/word-vectors-for-non-nlp-data-and-research-people-8d689c692353)
* [Deep Learning for NLP Best Practices](http://ruder.io/deep-learning-nlp-best-practices/)
* [åˆå­¦è€…æŒ‡å—ï¼šç¥ç»ç½‘ç»œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨](https://www.jiqizhixin.com/articles/2017-09-17-7)
* [A gentle introduction to Doc2Vec](https://medium.com/towards-data-science/a-gentle-introduction-to-doc2vec-db3e8c0cce5e)
* [Word embeddings in 2017: Trends and future directions](http://ruder.io/word-embeddings-2017)
* [Word Embedding in Deep Learning](https://analyticsdefined.com/word-embedding-in-deep-learning/)
* [Using pre-trained word embeddings in a Keras model](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)
* [Deep Learning for Natural Language Processing: 2016-2017](https://github.com/oxford-cs-deepnlp-2017/lectures)
* [åŸºäºSpark /Tensorflowä½¿ç”¨CNNå¤„ç†NLPçš„å°è¯•](http://www.jianshu.com/p/1afda7000d8e)
* [Understanding Convolutional Neural Networks for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)
* [Embedding projector - visualization of high-dimensional data](http://projector.tensorflow.org/)
* [Pytorch implementations of various Deep NLP models in cs-224n\(Stanford Univ\)](https://github.com/DSKSD/DeepNLP-models-Pytorch)
* [Stop Using word2vec](http://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/)
* [è®©æœºå™¨åƒäººä¸€æ ·äº¤æµï¼šæ–¯å¦ç¦æçºªä¸ºåšå£«æ¯•ä¸šè®ºæ–‡](https://www.jiqizhixin.com/articles/2017-11-14)
* [Gentle Introduction to Statistical Language Modeling and Neural Language Models](https://machinelearningmastery.com/statistical-language-modeling-and-neural-language-models/)
* [Dan Jurafsky & Chris Manning: Natural Language Processing \(great intro video series\)](https://www.youtube.com/watch?v=nfoudtpBV68&list=PL6397E4B26D00A269)

